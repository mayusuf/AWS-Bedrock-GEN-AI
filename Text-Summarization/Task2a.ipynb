{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fded102b",
   "metadata": {},
   "source": [
    "# Task 2a: Text summarization with small files with Titan Text Premier\n",
    "\n",
    "\n",
    "In this notebook, you ingest a small string of text directly into the Amazon Bedrock API (using the Titan Text model) and instruct it to summarize the input text. You can apply this approach to summarize call transcripts, meeting transcripts, books, articles, blog posts, and other relevant content when the input text length is within the context size limits of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca28279c",
   "metadata": {},
   "source": [
    "## Task 2a.1: Environment setup\n",
    "\n",
    "In this task, you set up your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66edf151",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create a service client by name using the default session.\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import boto3\n",
    "import botocore\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "module_path = \"..\"\n",
    "sys.path.append(os.path.abspath(module_path))\n",
    "\n",
    "bedrock_client = boto3.client('bedrock-runtime',region_name=os.environ.get(\"AWS_DEFAULT_REGION\", None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da4d9ee",
   "metadata": {},
   "source": [
    "\n",
    "## Task 2a.2: Writing prompt with text to be summarized\n",
    "\n",
    "In this task, you use a short passage of text with fewer tokens than the maximum length supported by the foundation model. As a sample input text for this lab, you use a paragraph from an [AWS blog post](https://aws.amazon.com/jp/blogs/machine-learning/announcing-new-tools-for-building-with-generative-ai-on-aws/) announcing Amazon Bedrock.\n",
    "\n",
    "The prompt starts with an instruction `Please provide a summary of the following text.`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ece0c069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_data = \"\"\"\n",
    "\n",
    "Please provide a summary of the following text:\n",
    "\n",
    "Results-oriented Full Stack Software Engineer with 6+ years of professional experience designing and developing reliable, \n",
    "robust, and highly available applications for the Engineering, E-Commerce, and Financial sectors. Skilled in building \n",
    "scalable, high-performance web applications using enterprise frameworks like Spring Boot, REST and Angular applying strong \n",
    "problem-solving and analytical skills. Proficient in Java, JPA, Hibernate, Kafka, MySQL, and PostgreSQL, with hands-on \n",
    "experience in React and jQuery.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efddbb0",
   "metadata": {},
   "source": [
    "## Task 2a.3: Creating request body with prompt and inference parameters \n",
    "\n",
    "In this task, you create the request body with the above prompt and inference parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60d191eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# request body\n",
    "body = json.dumps({\n",
    "    \"inputText\": prompt_data, \n",
    "    \"textGenerationConfig\":{\n",
    "        \"maxTokenCount\":2048,\n",
    "        \"stopSequences\":[],\n",
    "        \"temperature\":0,\n",
    "        \"topP\":0.9\n",
    "        }\n",
    "    }) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9f3326",
   "metadata": {},
   "source": [
    "## Task 2a.4: Invoke foundation model via Boto3\n",
    "\n",
    "In this task, you send an API request to Amazon Bedrock specifying the request parameters: `modelId`, `accept`, and `contentType`. Following the provided prompt, the foundation model in Amazon Bedrock then summarizes the input text.\n",
    "\n",
    "### Complete Output Generation\n",
    "\n",
    "By default, the Amazon Bedrock service generates the entire summary for a given prompt in a single output. This can be slow if the model output contains many tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f400d76",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS has announced Amazon Bedrock, a new service that provides access to foundation models (FMs) from AI21 Labs, Anthropic, Stability AI, and Amazon via an API. Bedrock aims to make it easy for customers to build and scale generative AI-based applications using FMs, democratizing access for all builders. The service offers a range of powerful FMs for text and images, including Amazon's Titan FMs, which consist of two new large language models (LLMs) that AWS is also announcing today. Bedrock's serverless experience allows customers to easily find the right model for their needs, customize FMs with their own data, and integrate and deploy them into their applications using familiar AWS tools and capabilities, without having to manage any infrastructure.\n"
     ]
    }
   ],
   "source": [
    "#model configuration and invoke the model\n",
    "modelId = 'amazon.titan-text-premier-v1:0' # change this to use a different version from the model provider\n",
    "accept = 'application/json'\n",
    "contentType = 'application/json'\n",
    "outputText = \"\\n\"\n",
    "\n",
    "try:\n",
    "\n",
    "    response = bedrock_client.invoke_model(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    outputText = response_body.get('results')[0].get('outputText')\n",
    "\n",
    "except botocore.exceptions.ClientError as error:\n",
    "    \n",
    "    if error.response['Error']['Code'] == 'AccessDeniedException':\n",
    "           print(f\"\\x1b[41m{error.response['Error']['Message']}\\\n",
    "                \\nTo troubeshoot this issue please refer to the following resources.\\\n",
    "                 \\nhttps://docs.aws.amazon.com/IAM/latest/UserGuide/troubleshoot_access-denied.html\\\n",
    "                 \\nhttps://docs.aws.amazon.com/bedrock/latest/userguide/security-iam.html\\x1b[0m\\n\")\n",
    "        \n",
    "    else:\n",
    "        raise error\n",
    "\n",
    "print(outputText)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c84a0",
   "metadata": {},
   "source": [
    "### Streaming Output Generation\n",
    "\n",
    "Next, you explore how to use Amazon Bedrock's invoke_model_with_response_stream API to stream model outputs so users can consume outputs as they are generated. Rather than generating the full output at once, this API returns a ResponseStream that sends smaller output chunks from the model as they are produced. You can display these streaming outputs in a continuous, consumable view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea3aa446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk': {'bytes': b'{\"outputText\":\"AWS\",\"index\":0}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" has\",\"index\":1}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" announced\",\"index\":2}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" Amazon\",\"index\":3}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" Bed\",\"index\":4}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"rock\",\"index\":5}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\",\",\"index\":6}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" a\",\"index\":7}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" new\",\"index\":8}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" service\",\"index\":9}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" that\",\"index\":10}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" provides\",\"index\":11}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" access\",\"index\":12}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" to\",\"index\":13}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" foundation\",\"index\":14}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" models\",\"index\":15}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" (\",\"index\":16}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"FM\",\"index\":17}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"s\",\"index\":18}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\")\",\"index\":19}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" from\",\"index\":20}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" AI\",\"index\":21}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"2\",\"index\":22}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"1\",\"index\":23}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" Labs\",\"index\":24}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\",\",\"index\":25}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" An\",\"index\":26}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"thro\",\"index\":27}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"pic\",\"index\":28}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\",\",\"index\":29}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" Stability\",\"index\":30}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" AI\",\"index\":31}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\",\",\"index\":32}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" and\",\"index\":33}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" Amazon\",\"index\":34}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" via\",\"index\":35}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" an\",\"index\":36}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" API\",\"index\":37}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\".\",\"index\":38}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" Bed\",\"index\":39}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"rock\",\"index\":40}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" aims\",\"index\":41}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" to\",\"index\":42}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" make\",\"index\":43}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" it\",\"index\":44}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" easy\",\"index\":45}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" for\",\"index\":46}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" customers\",\"index\":47}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" to\",\"index\":48}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" build\",\"index\":49}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" and\",\"index\":50}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" scale\",\"index\":51}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" gene\",\"index\":52}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"rative\",\"index\":53}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" AI\",\"index\":54}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"-\",\"index\":55}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"based\",\"index\":56}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" applications\",\"index\":57}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" using\",\"index\":58}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" FM\",\"index\":59}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"s\",\"index\":60}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\",\",\"index\":61}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" \",\"index\":62}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"democrat\",\"index\":63}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"izing\",\"index\":64}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" access\",\"index\":65}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" for\",\"index\":66}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" all\",\"index\":67}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" builders\",\"index\":68}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\".\",\"index\":69}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" The\",\"index\":70}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" service\",\"index\":71}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" offers\",\"index\":72}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" a\",\"index\":73}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" range\",\"index\":74}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" of\",\"index\":75}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" powerful\",\"index\":76}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" FM\",\"index\":77}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"s\",\"index\":78}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" for\",\"index\":79}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" text\",\"index\":80}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" and\",\"index\":81}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" images\",\"index\":82}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\",\",\"index\":83}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" including\",\"index\":84}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" Amazon\",\"index\":85}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"\\'\",\"index\":86}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"s\",\"index\":87}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" Titan\",\"index\":88}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" FM\",\"index\":89}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"s\",\"index\":90}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\",\",\"index\":91}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" which\",\"index\":92}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" consist\",\"index\":93}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" of\",\"index\":94}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" two\",\"index\":95}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" new\",\"index\":96}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" large\",\"index\":97}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" language\",\"index\":98}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" models\",\"index\":99}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" (\",\"index\":100}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"LL\",\"index\":101}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"M\",\"index\":102}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"s\",\"index\":103}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\")\",\"index\":104}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" announced\",\"index\":105}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" today\",\"index\":106}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\".\",\"index\":107}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" Bed\",\"index\":108}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"rock\",\"index\":109}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"\\'\",\"index\":110}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"s\",\"index\":111}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" server\",\"index\":112}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"less\",\"index\":113}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" experience\",\"index\":114}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" allows\",\"index\":115}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" customers\",\"index\":116}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" to\",\"index\":117}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" easily\",\"index\":118}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" find\",\"index\":119}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" the\",\"index\":120}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" right\",\"index\":121}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" model\",\"index\":122}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\",\",\"index\":123}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" customize\",\"index\":124}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" FM\",\"index\":125}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"s\",\"index\":126}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" with\",\"index\":127}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" their\",\"index\":128}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" own\",\"index\":129}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" data\",\"index\":130}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\",\",\"index\":131}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" and\",\"index\":132}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" integrate\",\"index\":133}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" and\",\"index\":134}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" deploy\",\"index\":135}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" them\",\"index\":136}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" into\",\"index\":137}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" their\",\"index\":138}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" applications\",\"index\":139}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" using\",\"index\":140}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" familiar\",\"index\":141}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" AWS\",\"index\":142}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" tools\",\"index\":143}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" and\",\"index\":144}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" capabilities\",\"index\":145}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\",\",\"index\":146}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" without\",\"index\":147}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" managing\",\"index\":148}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" any\",\"index\":149}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\" infrastructure\",\"index\":150}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\".\",\"index\":151}'}},\n",
       " {'chunk': {'bytes': b'{\"outputText\":\"\",\"completionReason\":\"FINISH\",\"totalOutputTextTokenCount\":152,\"index\":152,\"amazon-bedrock-invocationMetrics\":{\"inputTokenCount\":234,\"outputTokenCount\":152,\"invocationLatency\":3243,\"firstByteLatency\":638}}'}}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#invoke model with response stream\n",
    "modelId = 'amazon.titan-text-premier-v1:0'\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = list(stream)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01ab3461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display_markdown,Markdown,clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0148858",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "AWS has announced Amazon Bedrock, a new service that provides access to foundation models (FMs) from AI21 Labs, Anthropic, Stability AI, and Amazon via an API. Bedrock aims to make it easy for customers to build and scale generative AI-based applications using FMs, democratizing access for all builders. The service offers a range of powerful FMs for text and images, including Amazon's Titan FMs, which consist of two new large language models (LLMs) announced today. Bedrock's serverless experience allows customers to easily find the right model, customize FMs with their own data, and integrate and deploy them into their applications using familiar AWS tools and capabilities, without managing any infrastructure."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "modelId = 'amazon.titan-text-premier-v1:0'\n",
    "response = bedrock_client.invoke_model_with_response_stream(body=body, modelId=modelId, accept=accept, contentType=contentType)\n",
    "stream = response.get('body')\n",
    "output = []\n",
    "i = 1\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        chunk = event.get('chunk')\n",
    "        if chunk:\n",
    "            chunk_obj = json.loads(chunk.get('bytes').decode())\n",
    "            text = chunk_obj['outputText']\n",
    "            clear_output(wait=True)\n",
    "            output.append(text)\n",
    "            display_markdown(Markdown(''.join(output)))\n",
    "            i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e8ee83",
   "metadata": {},
   "source": [
    "You have now experimented with using the boto3 SDK to access the Amazon Bedrock API. This SDK provides basic programmatic access to Bedrock capabilities. By leveraging this API, you were able to implement two use cases: 1) Generating an entire text summary of AWS news content at once, and 2) Streaming the summary output in chunks for incremental processing.\n",
    "\n",
    "### Try it yourself\n",
    "- Change the prompts to your specific usecase and evaluate the output of different models.\n",
    "- Play with the token length to understand the latency and responsiveness of the service.\n",
    "- Apply different prompt engineering principles to get better outputs.\n",
    "\n",
    "### Cleanup\n",
    "\n",
    "You have completed this notebook. To move to the next part of the lab, do the following:\n",
    "\n",
    "- Close this notebook file and continue with **Task2b.ipynb**."
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "00878cbed564b904a98b4a19808853cb6b9988746b881ea025a8408713879bf5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
